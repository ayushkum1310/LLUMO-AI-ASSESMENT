{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ayush Kumar\n",
    "#### ayushpripl@gmail.com\n",
    "#### https://github.com/ayushkum1310\n",
    "##### This project is about to Finetune a LLM on a custom Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "splits = {'train': 'train.csv', 'validation': 'validation.csv', 'test': 'test.csv'}\n",
    "df = pd.read_csv(\"hf://datasets/zqz979/meta-review/\" + splits[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In this paper, the author investigates how to ...</td>\n",
       "      <td>This paper studies how to learn dexterous mani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>**Summary of contributions:** This paper propo...</td>\n",
       "      <td>This paper proposed a new family of losses for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This paper addresses the problem of MoE routin...</td>\n",
       "      <td>Mixture-of-Expert (MoE) models have demonstrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This paper discusses applications of variants ...</td>\n",
       "      <td>In this work, the authors conduct experiments ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The authors introduce the problem of telegraph...</td>\n",
       "      <td>This paper presents methods for telegraphic su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7687</th>\n",
       "      <td>The paper proposes a method to use CLIP for or...</td>\n",
       "      <td>The paper proposes a language-powered model fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7688</th>\n",
       "      <td>This work concerns the asymptotic behaviours o...</td>\n",
       "      <td>All reviewers are in agreement that the main f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7689</th>\n",
       "      <td>The paper surveys recent offline RL algorithms...</td>\n",
       "      <td>The main strengths of this paper are that (1) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7690</th>\n",
       "      <td>This paper proposes an algorithm for off-polic...</td>\n",
       "      <td>The reviewer concerns generally centered aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7691</th>\n",
       "      <td>This paper presents the NetHack Learning Datas...</td>\n",
       "      <td>This paper presents the NetHack Learning Data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7692 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Input  \\\n",
       "0     In this paper, the author investigates how to ...   \n",
       "1     **Summary of contributions:** This paper propo...   \n",
       "2     This paper addresses the problem of MoE routin...   \n",
       "3     This paper discusses applications of variants ...   \n",
       "4     The authors introduce the problem of telegraph...   \n",
       "...                                                 ...   \n",
       "7687  The paper proposes a method to use CLIP for or...   \n",
       "7688  This work concerns the asymptotic behaviours o...   \n",
       "7689  The paper surveys recent offline RL algorithms...   \n",
       "7690  This paper proposes an algorithm for off-polic...   \n",
       "7691  This paper presents the NetHack Learning Datas...   \n",
       "\n",
       "                                                 Output  \n",
       "0     This paper studies how to learn dexterous mani...  \n",
       "1     This paper proposed a new family of losses for...  \n",
       "2     Mixture-of-Expert (MoE) models have demonstrat...  \n",
       "3     In this work, the authors conduct experiments ...  \n",
       "4     This paper presents methods for telegraphic su...  \n",
       "...                                                 ...  \n",
       "7687  The paper proposes a language-powered model fo...  \n",
       "7688  All reviewers are in agreement that the main f...  \n",
       "7689  The main strengths of this paper are that (1) ...  \n",
       "7690  The reviewer concerns generally centered aroun...  \n",
       "7691   This paper presents the NetHack Learning Data...  \n",
       "\n",
       "[7692 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, validation, and test splits saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "ds = load_dataset(\"zqz979/meta-review\")\n",
    "\n",
    "# Define the file paths\n",
    "splits = {'train': 'train.csv', 'validation': 'validation.csv', 'test': 'test.csv'}\n",
    "\n",
    "# Save each split to CSV\n",
    "for split, filename in splits.items():\n",
    "    df = ds[split].to_pandas()  # Convert to pandas DataFrame\n",
    "    df.to_csv(filename, index=False)  # Save to CSV\n",
    "\n",
    "print(\"Train, validation, and test splits saved to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    input_texts = examples['meta_review']\n",
    "    target_texts = examples['summary']\n",
    "\n",
    "    # Normalize whitespace for both input and output\n",
    "    input_texts = [re.sub(r'\\s+', ' ', text).strip() for text in input_texts]\n",
    "    target_texts = [re.sub(r'\\s+', ' ', text).strip() for text in target_texts]\n",
    "\n",
    "    # Prefix input with a task indicator\n",
    "    inputs = [f\"summarize: {text}\" for text in input_texts]\n",
    "    \n",
    "    # Tokenize inputs and outputs\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(target_texts, max_length=150, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
